# Stem Separation - Vocal & Accompaniment


This project focuses on separating audio tracks into **vocal** and **accompaniment** stems using deep learning. The goal is to build an MVP model trained on the [MUSDB18](https://sigsep.github.io/datasets/musdb.html) dataset.

> ğŸ§‘â€ğŸ“ This is the **final project** for the **Artificial Intelligence with Deep Learning** postgraduate course at **Universitat PolitÃ¨cnica de Catalunya (UPC)**.


## ğŸ§  Objective

Train a model capable of separating a mixed music track into:
- **Vocal track**
- **Accompaniment track** (everything else)

## ğŸ“¦ Dataset

- **MUSDB18** â€“ a professionally produced dataset with 150 full-length music tracks, each with isolated stems (vocals, drums, bass, and others).
- Format: WAV files, multitrack
- Download instructions: [https://sigsep.github.io/datasets/musdb.html](https://sigsep.github.io/datasets/musdb.html)

## ğŸ› ï¸ Tech Stack

- Python
- PyTorch

Other TBD.

## ğŸš€ MVP Goal

Basic stem separation into:
`input.wav â†’ vocal.wav + accompaniment.wav`

## ğŸ”§ Setup
TBD

## â³ Status

MVP in development. Currently working on:
	â€¢	Data pipeline
	â€¢	Baseline model

## ğŸ“Œ Notes
	â€¢	MUSDB18 is not included in this repo. Download it manually and place it in the data/ directory.
	â€¢	Model and evaluation scripts to follow.